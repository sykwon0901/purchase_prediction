{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c99043",
   "metadata": {},
   "source": [
    "# 06_summary_tables_for_readme\n",
    "\n",
    "## Notebook Purpose\n",
    "- Load saved metrics and reports from `artifacts/metrics/` and `artifacts/reports/`\n",
    "- Auto-generate README-ready result summaries (classification, calibration, targeting)\n",
    "- Output `artifacts/reports/readme_snippets.md` for copy-paste into `README.md`\n",
    "- Print key highlights (Top1% / Top10% revenue_capture and purchase_rate) for recommended scores\n",
    "\n",
    "## Context\n",
    "- Shared inputs/outputs and execution conventions are documented in the project README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "475e1e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: C:\\Users\\seony\\Desktop\\personal_project\\purchase_prediction\n",
      "REPORTS_DIR: C:\\Users\\seony\\Desktop\\personal_project\\purchase_prediction\\artifacts\\reports\n",
      "METRICS_DIR: C:\\Users\\seony\\Desktop\\personal_project\\purchase_prediction\\artifacts\\metrics\n"
     ]
    }
   ],
   "source": [
    "# ============ Common PATH (local only) ============\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(r\"C:\\Users\\seony\\Desktop\\personal_project\\purchase_prediction\")\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "ARTIFACTS_DIR = PROJECT_ROOT / \"artifacts\"\n",
    "MODELS_DIR = ARTIFACTS_DIR / \"models\"\n",
    "PRED_DIR = ARTIFACTS_DIR / \"predictions\"\n",
    "REPORTS_DIR = ARTIFACTS_DIR / \"reports\"\n",
    "METRICS_DIR = ARTIFACTS_DIR / \"metrics\"\n",
    "FIGURES_DIR = ARTIFACTS_DIR / \"figures\"\n",
    "\n",
    "for d in [RAW_DIR, PROCESSED_DIR, MODELS_DIR, PRED_DIR, REPORTS_DIR, METRICS_DIR, FIGURES_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"REPORTS_DIR:\", REPORTS_DIR)\n",
    "print(\"METRICS_DIR:\", METRICS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419942f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e96617e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists:\n",
      " - purchase_metrics_valid.csv : True\n",
      " - purchase_metrics_test.csv : True\n",
      " - threshold_selection.csv : True\n",
      " - calibration_metrics_valid.csv : True\n",
      " - calibration_metrics_test.csv : True\n",
      " - predictions_test_calibrated.csv : True\n",
      " - alpha_beta_best.csv : True\n",
      " - revenue_capture_curve_compare.csv : True\n"
     ]
    }
   ],
   "source": [
    "# ============ Inputs (artifacts) ============\n",
    "PURCHASE_VALID = METRICS_DIR / \"purchase_metrics_valid.csv\"\n",
    "PURCHASE_TEST  = METRICS_DIR / \"purchase_metrics_test.csv\"\n",
    "THRESH_SEL     = METRICS_DIR / \"threshold_selection.csv\"\n",
    "\n",
    "CAL_VALID = METRICS_DIR / \"calibration_metrics_valid.csv\"\n",
    "CAL_TEST  = METRICS_DIR / \"calibration_metrics_test.csv\"\n",
    "\n",
    "PRED_TEST_CAL = PRED_DIR / \"predictions_test_calibrated.csv\"\n",
    "PRED_VALID_CAL = PRED_DIR / \"predictions_valid_calibrated.csv\"\n",
    "\n",
    "ALPHA_BETA_BEST = REPORTS_DIR / \"alpha_beta_best.csv\"\n",
    "\n",
    "CURVE_COMPARE = REPORTS_DIR / \"revenue_capture_curve_compare.csv\"\n",
    "\n",
    "README_SNIPPETS_OUT = REPORTS_DIR / \"readme_snippets.md\"\n",
    "\n",
    "print(\"Exists:\")\n",
    "for p in [PURCHASE_VALID, PURCHASE_TEST, THRESH_SEL, CAL_VALID, CAL_TEST, PRED_TEST_CAL, ALPHA_BETA_BEST, CURVE_COMPARE]:\n",
    "    print(\" -\", p.name, \":\", p.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5260b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ Helpers ============\n",
    "def _load_csv(path: Path) -> pd.DataFrame:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing file: {path}\")\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def _fmt(x, nd=4):\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    try:\n",
    "        return f\"{float(x):.{nd}f}\"\n",
    "    except Exception:\n",
    "        return str(x)\n",
    "\n",
    "def _pick_best_model(valid_df: pd.DataFrame, key: str = \"pr_auc\") -> str:\n",
    "    # Expect a column called \"model\"\n",
    "    if \"model\" not in valid_df.columns:\n",
    "        raise ValueError(\"purchase_metrics_valid.csv must have a 'model' column.\")\n",
    "    if key not in valid_df.columns:\n",
    "        raise ValueError(f\"purchase_metrics_valid.csv missing key column: {key}\")\n",
    "    return str(valid_df.sort_values(key, ascending=False).iloc[0][\"model\"])\n",
    "\n",
    "def _topk_from_compare(compare_df: pd.DataFrame, score: str, frac: float) -> pd.Series:\n",
    "    sub = compare_df[(compare_df[\"score\"] == score) & (compare_df[\"top_frac\"] == frac)]\n",
    "    if len(sub) == 0:\n",
    "        # fallback: nearest\n",
    "        s2 = compare_df[compare_df[\"score\"] == score].copy()\n",
    "        i = int(np.argmin(np.abs(s2[\"top_frac\"].to_numpy() - frac)))\n",
    "        return s2.iloc[i]\n",
    "    return sub.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d695e869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best purchase model by VALID PR-AUC: catboost\n",
      "Calibration methods in predictions file: ['isotonic']\n",
      "Best alpha/beta (from file): {'alpha': 2.0, 'beta': 0.25, 'revenue_capture@1pct_valid': 0.3988299786298735, 'revenue_capture@10pct_valid': 0.7934561960973923, 'purchase_rate@1pct_valid': 0.0484044460380064}\n"
     ]
    }
   ],
   "source": [
    "# ============ Load artifacts ============\n",
    "purchase_valid = _load_csv(PURCHASE_VALID)\n",
    "purchase_test  = _load_csv(PURCHASE_TEST)\n",
    "\n",
    "cal_valid = _load_csv(CAL_VALID)\n",
    "cal_test  = _load_csv(CAL_TEST)\n",
    "\n",
    "pred_test = _load_csv(PRED_TEST_CAL)\n",
    "pred_valid = _load_csv(PRED_VALID_CAL)\n",
    "\n",
    "curve_compare = _load_csv(CURVE_COMPARE)\n",
    "ab_best = _load_csv(ALPHA_BETA_BEST)\n",
    "\n",
    "best_model = _pick_best_model(purchase_valid, key=\"pr_auc\")\n",
    "\n",
    "print(\"Best purchase model by VALID PR-AUC:\", best_model)\n",
    "print(\"Calibration methods in predictions file:\", sorted(pred_test[\"p_cal_method\"].astype(str).unique().tolist()))\n",
    "print(\"Best alpha/beta (from file):\", ab_best.iloc[0].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3abc9e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>base_rate</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>logloss</th>\n",
       "      <th>brier</th>\n",
       "      <th>threshold_f1_max</th>\n",
       "      <th>threshold_f1_max_precision</th>\n",
       "      <th>threshold_f1_max_recall</th>\n",
       "      <th>threshold_f1_max_f1</th>\n",
       "      <th>...</th>\n",
       "      <th>threshold_precision_10pct</th>\n",
       "      <th>threshold_precision_10pct_precision</th>\n",
       "      <th>threshold_precision_10pct_recall</th>\n",
       "      <th>threshold_precision_10pct_f1</th>\n",
       "      <th>threshold_precision_10pct_accuracy</th>\n",
       "      <th>threshold_precision_10pct_tp</th>\n",
       "      <th>threshold_precision_10pct_fp</th>\n",
       "      <th>threshold_precision_10pct_tn</th>\n",
       "      <th>threshold_precision_10pct_fn</th>\n",
       "      <th>threshold_precision_10pct_predicted_positive_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>valid</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.877990</td>\n",
       "      <td>0.046840</td>\n",
       "      <td>0.413211</td>\n",
       "      <td>0.123886</td>\n",
       "      <td>0.955583</td>\n",
       "      <td>0.104874</td>\n",
       "      <td>0.123264</td>\n",
       "      <td>0.113328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954489</td>\n",
       "      <td>0.099863</td>\n",
       "      <td>0.126736</td>\n",
       "      <td>0.111706</td>\n",
       "      <td>0.995836</td>\n",
       "      <td>73</td>\n",
       "      <td>658</td>\n",
       "      <td>277613</td>\n",
       "      <td>503</td>\n",
       "      <td>0.002622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.871106</td>\n",
       "      <td>0.040651</td>\n",
       "      <td>0.412595</td>\n",
       "      <td>0.123964</td>\n",
       "      <td>0.955583</td>\n",
       "      <td>0.093923</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.097795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954489</td>\n",
       "      <td>0.089831</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.097248</td>\n",
       "      <td>0.996111</td>\n",
       "      <td>53</td>\n",
       "      <td>537</td>\n",
       "      <td>251989</td>\n",
       "      <td>447</td>\n",
       "      <td>0.002332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   split  base_rate   roc_auc    pr_auc   logloss     brier  threshold_f1_max  \\\n",
       "0  valid   0.002066  0.877990  0.046840  0.413211  0.123886          0.955583   \n",
       "1   test   0.001976  0.871106  0.040651  0.412595  0.123964          0.955583   \n",
       "\n",
       "   threshold_f1_max_precision  threshold_f1_max_recall  threshold_f1_max_f1  \\\n",
       "0                    0.104874                 0.123264             0.113328   \n",
       "1                    0.093923                 0.102000             0.097795   \n",
       "\n",
       "   ...  threshold_precision_10pct  threshold_precision_10pct_precision  \\\n",
       "0  ...                   0.954489                             0.099863   \n",
       "1  ...                   0.954489                             0.089831   \n",
       "\n",
       "   threshold_precision_10pct_recall  threshold_precision_10pct_f1  \\\n",
       "0                          0.126736                      0.111706   \n",
       "1                          0.106000                      0.097248   \n",
       "\n",
       "   threshold_precision_10pct_accuracy  threshold_precision_10pct_tp  \\\n",
       "0                            0.995836                            73   \n",
       "1                            0.996111                            53   \n",
       "\n",
       "   threshold_precision_10pct_fp  threshold_precision_10pct_tn  \\\n",
       "0                           658                        277613   \n",
       "1                           537                        251989   \n",
       "\n",
       "   threshold_precision_10pct_fn  \\\n",
       "0                           503   \n",
       "1                           447   \n",
       "\n",
       "   threshold_precision_10pct_predicted_positive_rate  \n",
       "0                                           0.002622  \n",
       "1                                           0.002332  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============ Build purchase summary table (VALID/TEST) ============\n",
    "# Expected columns produced by notebook 02\n",
    "cols_core = [\"base_rate\", \"roc_auc\", \"pr_auc\", \"logloss\", \"brier\"]\n",
    "cols_thr1 = [\n",
    "    \"threshold_f1_max\", \"threshold_f1_max_precision\", \"threshold_f1_max_recall\", \"threshold_f1_max_f1\",\n",
    "    \"threshold_f1_max_accuracy\", \"threshold_f1_max_tp\", \"threshold_f1_max_fp\", \"threshold_f1_max_tn\",\n",
    "    \"threshold_f1_max_fn\", \"threshold_f1_max_predicted_positive_rate\"\n",
    "]\n",
    "cols_thr2 = [\n",
    "    \"threshold_precision_10pct\", \"threshold_precision_10pct_precision\", \"threshold_precision_10pct_recall\",\n",
    "    \"threshold_precision_10pct_f1\", \"threshold_precision_10pct_accuracy\", \"threshold_precision_10pct_tp\",\n",
    "    \"threshold_precision_10pct_fp\", \"threshold_precision_10pct_tn\", \"threshold_precision_10pct_fn\",\n",
    "    \"threshold_precision_10pct_predicted_positive_rate\"\n",
    "]\n",
    "\n",
    "def _row_for(model_name: str, df: pd.DataFrame) -> pd.Series:\n",
    "    s = df[df[\"model\"] == model_name]\n",
    "    if len(s) == 0:\n",
    "        raise ValueError(f\"Model '{model_name}' not found in metrics table.\")\n",
    "    return s.iloc[0]\n",
    "\n",
    "pv = _row_for(best_model, purchase_valid)\n",
    "pt = _row_for(best_model, purchase_test)\n",
    "\n",
    "purchase_summary = pd.DataFrame([\n",
    "    {\"split\": \"valid\", **{k: pv.get(k, np.nan) for k in (cols_core + cols_thr1 + cols_thr2)}},\n",
    "    {\"split\": \"test\",  **{k: pt.get(k, np.nan) for k in (cols_core + cols_thr1 + cols_thr2)}},\n",
    "])\n",
    "\n",
    "display(purchase_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdd58ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>method</th>\n",
       "      <th>base_rate</th>\n",
       "      <th>p_mean</th>\n",
       "      <th>logloss</th>\n",
       "      <th>brier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>valid</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.285296</td>\n",
       "      <td>0.413211</td>\n",
       "      <td>0.123886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>valid</td>\n",
       "      <td>platt</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.011697</td>\n",
       "      <td>0.002009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valid</td>\n",
       "      <td>isotonic</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.011590</td>\n",
       "      <td>0.002003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.284399</td>\n",
       "      <td>0.412595</td>\n",
       "      <td>0.123964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>platt</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.011574</td>\n",
       "      <td>0.001931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test</td>\n",
       "      <td>isotonic</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>0.011697</td>\n",
       "      <td>0.001932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split    method  base_rate    p_mean   logloss     brier\n",
       "0  valid       raw   0.002066  0.285296  0.413211  0.123886\n",
       "1  valid     platt   0.002066  0.002088  0.011697  0.002009\n",
       "2  valid  isotonic   0.002066  0.002066  0.011590  0.002003\n",
       "3   test       raw   0.001976  0.284399  0.412595  0.123964\n",
       "4   test     platt   0.001976  0.002069  0.011574  0.001931\n",
       "5   test  isotonic   0.001976  0.002043  0.011697  0.001932"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============ Build calibration summary table (VALID/TEST) ============\n",
    "# calibration_metrics_{split}.csv is expected to include rows for raw/platt/isotonic\n",
    "def _cal_block(df: pd.DataFrame, split_name: str) -> pd.DataFrame:\n",
    "    # support either {method, base_rate, logloss, brier, p_mean, p_p99, p_max} or a superset\n",
    "    need = [\"method\", \"base_rate\", \"logloss\", \"brier\", \"p_mean\"]\n",
    "    missing = [c for c in need if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in calibration metrics: {missing}\")\n",
    "    out = df.copy()\n",
    "    out.insert(0, \"split\", split_name)\n",
    "    return out[[\"split\", \"method\", \"base_rate\", \"p_mean\", \"logloss\", \"brier\"]]\n",
    "\n",
    "cal_summary = pd.concat([\n",
    "    _cal_block(cal_valid, \"valid\"),\n",
    "    _cal_block(cal_test, \"test\")\n",
    "], axis=0, ignore_index=True)\n",
    "\n",
    "display(cal_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7530c52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores available: ['ev', 'ev_cal', 'ev_cal_isotonic', 'ev_cal_platt', 'p_cal', 'p_cal_isotonic', 'p_cal_platt', 'p_hat', 'tuned']\n",
      "Recommended (conversion): p_cal\n",
      "Recommended (revenue): ev_cal_platt\n",
      "Recommended (hybrid): tuned\n"
     ]
    }
   ],
   "source": [
    "# ============ Choose recommended scores (objective-driven) ============\n",
    "# Candidates present in curve_compare (created by notebook 05)\n",
    "scores = sorted(curve_compare[\"score\"].unique().tolist())\n",
    "print(\"Scores available:\", scores)\n",
    "\n",
    "# Objective A: conversion -> maximize purchase_rate@1% on TEST among p-based scores\n",
    "p_candidates = [s for s in scores if s.startswith(\"p_\")]\n",
    "conv_best = max(\n",
    "    p_candidates,\n",
    "    key=lambda s: float(_topk_from_compare(curve_compare, s, 0.01)[\"purchase_rate@k\"])\n",
    ")\n",
    "\n",
    "# Objective B: revenue -> maximize revenue_capture@1% on TEST among EV-cal candidates\n",
    "ev_candidates = [s for s in scores if s.startswith(\"ev_cal\")]\n",
    "rev_best = max(\n",
    "    ev_candidates,\n",
    "    key=lambda s: float(_topk_from_compare(curve_compare, s, 0.01)[\"revenue_capture@k\"])\n",
    ")\n",
    "\n",
    "# Objective C: hybrid -> use tuned\n",
    "hybrid_best = \"tuned\" if \"tuned\" in scores else None\n",
    "\n",
    "print(\"Recommended (conversion):\", conv_best)\n",
    "print(\"Recommended (revenue):\", rev_best)\n",
    "print(\"Recommended (hybrid):\", hybrid_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "505141f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>top_frac</th>\n",
       "      <th>revenue_capture</th>\n",
       "      <th>purchase_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ev_cal_platt</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.451205</td>\n",
       "      <td>0.045041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tuned</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.434903</td>\n",
       "      <td>0.039905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p_cal</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.400094</td>\n",
       "      <td>0.053734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ev_cal_platt</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.814042</td>\n",
       "      <td>0.012449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tuned</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.794817</td>\n",
       "      <td>0.012963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p_cal</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.748856</td>\n",
       "      <td>0.013121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          score  top_frac  revenue_capture  purchase_rate\n",
       "2  ev_cal_platt      0.01         0.451205       0.045041\n",
       "4         tuned      0.01         0.434903       0.039905\n",
       "0         p_cal      0.01         0.400094       0.053734\n",
       "3  ev_cal_platt      0.10         0.814042       0.012449\n",
       "5         tuned      0.10         0.794817       0.012963\n",
       "1         p_cal      0.10         0.748856       0.013121"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============ Top-1% / Top-10% numbers for README ============\n",
    "def _kpi_row(score: str, frac: float) -> dict:\n",
    "    r = _topk_from_compare(curve_compare, score, frac)\n",
    "    return {\n",
    "        \"score\": score,\n",
    "        \"top_frac\": float(frac),\n",
    "        \"revenue_capture\": float(r[\"revenue_capture@k\"]),\n",
    "        \"purchase_rate\": float(r[\"purchase_rate@k\"]),\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "for s in [conv_best, rev_best, hybrid_best]:\n",
    "    if s is None:\n",
    "        continue\n",
    "    rows.append(_kpi_row(s, 0.01))\n",
    "    rows.append(_kpi_row(s, 0.10))\n",
    "\n",
    "readme_topk = pd.DataFrame(rows).sort_values([\"top_frac\", \"revenue_capture\"], ascending=[True, False])\n",
    "display(readme_topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9023edb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\seony\\Desktop\\personal_project\\purchase_prediction\\artifacts\\reports\\readme_snippets.md\n",
      "\n",
      "--- README_SNIPPETS (preview) ---\n",
      "\n",
      "# Results summary (auto-generated)\n",
      "\n",
      "## Purchase prediction (classification)\n",
      "\n",
      "Best model by VALID PR-AUC: **catboost**\n",
      "\n",
      "- **VALID** base_rate=0.002066, ROC-AUC=0.8780, PR-AUC=0.0468, LogLoss=0.4132, Brier=0.1239\n",
      "  - F1-max thr=0.9556: P=0.1049, R=0.1233, F1=0.1133, PPR=0.0024\n",
      "  - P>=10% thr=0.9545: P=0.0999, R=0.1267, F1=0.1117, PPR=0.0026\n",
      "- **TEST** base_rate=0.001976, ROC-AUC=0.8711, PR-AUC=0.0407, LogLoss=0.4126, Brier=0.1240\n",
      "  - F1-max thr=0.9556: P=0.0939, R=0.1020, F1=0.0978, PPR=0.0021\n",
      "  - P>=10% thr=0.9545: P=0.0898, R=0.1060, F1=0.0972, PPR=0.0023\n",
      "\n",
      "## Calibration effect\n",
      "\n",
      "Best method by VALID logloss: **isotonic**\n",
      "\n",
      "- **VALID raw** p_mean=0.285296, logloss=0.413211, brier=0.123886\n",
      "- **VALID platt** p_mean=0.002088, logloss=0.011697, brier=0.002009\n",
      "- **VALID isotonic** p_mean=0.002066, logloss=0.011590, brier=0.002003\n",
      "- **TEST raw** p_mean=0.284399, logloss=0.412595, brier=0.123964\n",
      "- **TEST platt** p_mean=0.002069, logloss=0.011574, brier=0.001931\n",
      "- **TEST isotonic** p_mean=0.002043, logloss=0.011697, brier=0.001932\n",
      "\n",
      "## Campaign targeting (ranking) — recommendations\n",
      "\n",
      "- **Conversion-first**: use **p_cal** (maximize purchase_rate@1%)\n",
      "- **Revenue-first**: use **ev_cal_platt** (maximize revenue_capture@1%)\n",
      "- **Hybrid**: use **tuned** (tuned score), best params on VALID: alpha=2.0, beta=0.25\n",
      "\n",
      "Top-k highlights (TEST):\n",
      "\n",
      "- **p_cal**: Top1% revenue_capture=0.4001, purchase_rate=0.0537 | Top10% revenue_capture=0.7489, purchase_rate=0.0131\n",
      "- **ev_cal_platt**: Top1% revenue_capture=0.4512, purchase_rate=0.0450 | Top10% revenue_capture=0.8140, purchase_rate=0.0124\n",
      "- **tuned**: Top1% revenue_capture=0.4349, purchase_rate=0.0399 | Top10% revenue_capture=0.7948, purchase_rate=0.0130\n",
      "\n",
      "## Notes / limitations\n",
      "\n",
      "- This evaluation uses weekly snapshots with a fixed history window (23d) and label window (7d).\n",
      "- Results reflect one time span (2020-09 to 2021-02). For stronger confidence, extend to longer periods and run rolling backtests (multiple cutoffs) to monitor drift in PR-AUC, \n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============ Generate README snippets (markdown) ============\n",
    "# Purchase metrics section (compact)\n",
    "def _purchase_lines(split: str, s: pd.Series) -> str:\n",
    "    return \"\\n\".join([\n",
    "        f\"- **{split.upper()}** base_rate={_fmt(s['base_rate'],6)}, ROC-AUC={_fmt(s['roc_auc'])}, PR-AUC={_fmt(s['pr_auc'])}, LogLoss={_fmt(s['logloss'])}, Brier={_fmt(s['brier'])}\",\n",
    "        f\"  - F1-max thr={_fmt(s['threshold_f1_max'])}: P={_fmt(s['threshold_f1_max_precision'])}, R={_fmt(s['threshold_f1_max_recall'])}, F1={_fmt(s['threshold_f1_max_f1'])}, PPR={_fmt(s['threshold_f1_max_predicted_positive_rate'])}\",\n",
    "        f\"  - P>=10% thr={_fmt(s['threshold_precision_10pct'])}: P={_fmt(s['threshold_precision_10pct_precision'])}, R={_fmt(s['threshold_precision_10pct_recall'])}, F1={_fmt(s['threshold_precision_10pct_f1'])}, PPR={_fmt(s['threshold_precision_10pct_predicted_positive_rate'])}\",\n",
    "    ])\n",
    "\n",
    "# Calibration section\n",
    "def _cal_lines(split: str, df: pd.DataFrame) -> str:\n",
    "    rows = []\n",
    "    for method in [\"raw\", \"platt\", \"isotonic\"]:\n",
    "        sub = df[(df[\"split\"] == split) & (df[\"method\"] == method)]\n",
    "        if len(sub) == 0:\n",
    "            continue\n",
    "        r = sub.iloc[0]\n",
    "        rows.append(f\"- **{split.upper()} {method}** p_mean={_fmt(r['p_mean'],6)}, logloss={_fmt(r['logloss'],6)}, brier={_fmt(r['brier'],6)}\")\n",
    "    return \"\\n\".join(rows)\n",
    "\n",
    "# Targeting section\n",
    "def _topk_line(score: str) -> str:\n",
    "    r1 = _topk_from_compare(curve_compare, score, 0.01)\n",
    "    r10 = _topk_from_compare(curve_compare, score, 0.10)\n",
    "    return (f\"- **{score}**: Top1% revenue_capture={_fmt(r1['revenue_capture@k'],4)}, purchase_rate={_fmt(r1['purchase_rate@k'],4)} | \"\n",
    "            f\"Top10% revenue_capture={_fmt(r10['revenue_capture@k'],4)}, purchase_rate={_fmt(r10['purchase_rate@k'],4)}\")\n",
    "\n",
    "method_in_file = str(pred_test[\"p_cal_method\"].astype(str).unique()[0])\n",
    "ab = ab_best.iloc[0].to_dict()\n",
    "alpha = ab.get(\"alpha\", \"\")\n",
    "beta = ab.get(\"beta\", \"\")\n",
    "\n",
    "md = []\n",
    "md.append(\"# Results summary (auto-generated)\\n\")\n",
    "md.append(\"## Purchase prediction (classification)\\n\")\n",
    "md.append(f\"Best model by VALID PR-AUC: **{best_model}**\\n\")\n",
    "md.append(_purchase_lines(\"valid\", purchase_summary.loc[purchase_summary['split']=='valid'].iloc[0]))\n",
    "md.append(_purchase_lines(\"test\",  purchase_summary.loc[purchase_summary['split']=='test'].iloc[0]))\n",
    "md.append(\"\\n## Calibration effect\\n\")\n",
    "md.append(f\"Best method by VALID logloss: **{method_in_file}**\\n\")\n",
    "md.append(_cal_lines(\"valid\", cal_summary))\n",
    "md.append(_cal_lines(\"test\",  cal_summary))\n",
    "\n",
    "md.append(\"\\n## Campaign targeting (ranking) — recommendations\\n\")\n",
    "md.append(f\"- **Conversion-first**: use **{conv_best}** (maximize purchase_rate@1%)\")\n",
    "md.append(f\"- **Revenue-first**: use **{rev_best}** (maximize revenue_capture@1%)\")\n",
    "if hybrid_best:\n",
    "    md.append(f\"- **Hybrid**: use **{hybrid_best}** (tuned score), best params on VALID: alpha={alpha}, beta={beta}\")\n",
    "md.append(\"\\nTop-k highlights (TEST):\\n\")\n",
    "md.append(_topk_line(conv_best))\n",
    "md.append(_topk_line(rev_best))\n",
    "if hybrid_best:\n",
    "    md.append(_topk_line(hybrid_best))\n",
    "\n",
    "md.append(\"\\n## Notes / limitations\\n\")\n",
    "md.append(\"- This evaluation uses weekly snapshots with a fixed history window (23d) and label window (7d).\")\n",
    "md.append(\"- Results reflect one time span (2020-09 to 2021-02). For stronger confidence, extend to longer periods and run rolling backtests (multiple cutoffs) to monitor drift in PR-AUC, calibration (p_mean/logloss), and top-k revenue capture.\\n\")\n",
    "\n",
    "md_text = \"\\n\".join(md)\n",
    "\n",
    "with open(README_SNIPPETS_OUT, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(md_text)\n",
    "\n",
    "print(\"Saved:\", README_SNIPPETS_OUT)\n",
    "print(\"\\n--- README_SNIPPETS (preview) ---\\n\")\n",
    "print(md_text[:2000] + (\"\\n...\\n\" if len(md_text) > 2000 else \"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
