{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a5fb3b6-c4ad-4669-941e-d02080073d5c",
   "metadata": {},
   "source": [
    "# 03_train_value_model.ipynb\n",
    "\n",
    "## Notebook Purpose\n",
    "- Train a **conditional value model** on **buyers only** (target: `log1p(y_revenue)`).\n",
    "- Generate `rev_hat` for **all VALID/TEST snapshots** (predicted conditional revenue) and compute expected value:\n",
    "  - `ev = p_hat * rev_hat` (Expected Value = purchase probability * predicted revenue)\n",
    "- Update and overwrite prediction files in `artifacts/predictions/`:\n",
    "  - `predictions_valid_raw.csv` (adds `rev_hat`, `ev`)\n",
    "  - `predictions_test_raw.csv` (adds `rev_hat`, `ev`)\n",
    "- Save the value model artifact to `artifacts/models/`.\n",
    "- Save value model evaluation metrics to `artifacts/metrics/value_metrics_valid.csv`.\n",
    "\n",
    "## Context\n",
    "- Shared inputs/outputs and execution conventions are documented in the project README.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Outcome (Read this first)\n",
    "- This notebook implements a **two-stage (hurdle) setup**:\n",
    "  - Stage A (Notebook 02): purchase probability `p_hat`\n",
    "  - Stage B (this notebook): conditional revenue `rev_hat | purchase=1`\n",
    "  - Combined: `ev = p_hat * rev_hat` for ranking and campaign value targeting\n",
    "- Value model was trained and validated on a **small buyer-only sample**:\n",
    "  - Buyers: **train=939**, **valid=576** (base rate is very low overall, so buyer-only data is limited)\n",
    "- Validation quality (buyers only):\n",
    "  - `rmse_log1p = 0.8170`, `mae_log1p = 0.5655`\n",
    "  - Revenue-space errors are large (heavy-tailed revenue), so the log-target is the practical training target:\n",
    "    - `rmse_revenue = 413.48`, `mae_revenue = 182.61` (valid buyers)\n",
    "- `rev_hat` is produced for every snapshot (including non-buyers) because it is interpreted as:\n",
    "  - “If this user buys in the next 7 days, what revenue is expected?”\n",
    "\n",
    "---\n",
    "\n",
    "## Experiment Design\n",
    "- **Conditional modeling choice (buyers-only)**:\n",
    "  - Revenue is zero-inflated (most users do not buy), so modeling `y_revenue` directly mixes two problems:\n",
    "    - (1) purchase likelihood and (2) order value\n",
    "  - This notebook isolates (2) by fitting on `y_purchase=1` only.\n",
    "- **Target transformation**:\n",
    "  - Fit on `log1p(y_revenue)` to reduce heavy-tail impact and stabilize training.\n",
    "  - Convert predictions back to revenue space to create `rev_hat` (positive-valued).\n",
    "- **Splits and leakage control**:\n",
    "  - Uses the same time-based TRAIN/VALID/TEST snapshot splits as the purchase model.\n",
    "  - Trains on TRAIN buyers, evaluates on VALID buyers, then scores VALID/TEST snapshots.\n",
    "\n",
    "---\n",
    "\n",
    "## Model Choice (Value Model: **CatBoost Regressor**)\n",
    "  - Selected to produce a **stable `rev_hat`** that does not destabilize downstream **EV ranking** (`ev = p_hat * rev_hat`), where overestimation in the value head can dominate the combined score.\n",
    "  - A practical choice for **buyer-only training** (small sample, noisy tabular signals): CatBoost tends to be **robust with strong default performance** and lower sensitivity to extensive feature scaling/normalization.\n",
    "  - **Lower tuning burden**: good performance is often achievable with minimal hyperparameter search, which is desirable when the objective is a **quick, reliable baseline value model** rather than squeezing out marginal RMSE gains.\n",
    "  - **LightGBM trade-off**: while often faster, LightGBM typically requires more careful tuning (e.g., leaves/regularization) to achieve similarly stable generalization in small, heavy-tailed revenue settings; given the EV multiplication, this extra instability risk is not worth it at this stage.\n",
    "  - Early stopping selects the best iteration on **VALID buyers** and shrinks the model accordingly.\n",
    "\n",
    "---\n",
    "\n",
    "## Sanity Checks / Interpretation Notes\n",
    "- `rev_hat` distribution summaries (all snapshots) indicate stable scale across VALID/TEST.\n",
    "- Buyer vs non-buyer separation is directionally correct on VALID:\n",
    "  - Mean `rev_hat` is higher for `y_purchase=1` than `y_purchase=0`.\n",
    "  - Mean `ev` is substantially higher for buyers than non-buyers (as expected since `ev` includes `p_hat`).\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs\n",
    "- Model artifact:\n",
    "  - `artifacts/models/value_model_catboost.cbm`\n",
    "- Metrics:\n",
    "  - `artifacts/metrics/value_metrics_valid.csv`\n",
    "- Updated prediction files (adds `rev_hat`, `ev`):\n",
    "  - `artifacts/predictions/predictions_valid_raw.csv`\n",
    "  - `artifacts/predictions/predictions_test_raw.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "707b46d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: C:\\Users\\seony\\Desktop\\personal_project\\purchase_prediction\n",
      "PROCESSED_DIR: C:\\Users\\seony\\Desktop\\personal_project\\purchase_prediction\\data\\processed\n",
      "PRED_DIR: C:\\Users\\seony\\Desktop\\personal_project\\purchase_prediction\\artifacts\\predictions\n"
     ]
    }
   ],
   "source": [
    "# ============ Common PATH / ENV block ============\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(r\"C:\\Users\\seony\\Desktop\\personal_project\\purchase_prediction\")\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "ARTIFACTS_DIR = PROJECT_ROOT / \"artifacts\"\n",
    "MODELS_DIR = ARTIFACTS_DIR / \"models\"\n",
    "PRED_DIR = ARTIFACTS_DIR / \"predictions\"\n",
    "REPORTS_DIR = ARTIFACTS_DIR / \"reports\"\n",
    "METRICS_DIR = ARTIFACTS_DIR / \"metrics\"\n",
    "FIGURES_DIR = ARTIFACTS_DIR / \"figures\"\n",
    "\n",
    "for d in [RAW_DIR, PROCESSED_DIR, MODELS_DIR, PRED_DIR, REPORTS_DIR, METRICS_DIR, FIGURES_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"PROCESSED_DIR:\", PROCESSED_DIR)\n",
    "print(\"PRED_DIR:\", PRED_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a28c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ Imports ============\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677986f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER_DATASET_PATH: C:\\Users\\seony\\Desktop\\personal_project\\purchase_prediction\\data\\processed\\user_dataset_hist23_label7_snapshots_v1.parquet\n",
      "PRED_VALID_RAW: C:\\Users\\seony\\Desktop\\personal_project\\purchase_prediction\\artifacts\\predictions\\predictions_valid_raw.csv | exists: True\n",
      "PRED_TEST_RAW : C:\\Users\\seony\\Desktop\\personal_project\\purchase_prediction\\artifacts\\predictions\\predictions_test_raw.csv | exists: True\n"
     ]
    }
   ],
   "source": [
    "# ============ Inputs / outputs ============\n",
    "USER_DATASET_PATH = PROCESSED_DIR / \"user_dataset_hist23_label7_snapshots_v1.parquet\"\n",
    "\n",
    "PRED_VALID_RAW = PRED_DIR / \"predictions_valid_raw.csv\"\n",
    "PRED_TEST_RAW  = PRED_DIR / \"predictions_test_raw.csv\"\n",
    "\n",
    "VALUE_MODEL_OUT = MODELS_DIR / \"value_model_catboost.cbm\"\n",
    "VALUE_METRICS_OUT = METRICS_DIR / \"value_metrics_valid.csv\"\n",
    "\n",
    "print(\"USER_DATASET_PATH:\", USER_DATASET_PATH)\n",
    "print(\"PRED_VALID_RAW:\", PRED_VALID_RAW, \"| exists:\", PRED_VALID_RAW.exists())\n",
    "print(\"PRED_TEST_RAW :\", PRED_TEST_RAW,  \"| exists:\", PRED_TEST_RAW.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ffc0101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (1183222, 19)\n",
      "n_features: 14\n",
      "features: ['n_events', 'n_sessions', 'n_products', 'n_categories', 'price_mean', 'price_max', 'price_min', 'n_cart', 'n_purchase_hist', 'n_view', 'recency_days', 'cart_view_ratio', 'purchase_cart_ratio_hist', 'events_per_session']\n",
      "Splits: (651349, 19) (278847, 19) (253026, 19)\n",
      "Base rates: 0.0014416234614622883 0.0020656489042378077 0.0019760815094101002\n",
      "Buyers (train/valid): 939 576\n",
      "Train buyers revenue summary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     939.000000\n",
       "mean      242.158371\n",
       "std       337.849356\n",
       "min         1.570000\n",
       "50%       126.680000\n",
       "90%       598.607983\n",
       "95%       965.560980\n",
       "99%      1830.556357\n",
       "max      2862.850098\n",
       "Name: y_revenue, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============ Load user snapshot dataset ============\n",
    "df = pd.read_parquet(USER_DATASET_PATH)\n",
    "print(\"Loaded:\", df.shape)\n",
    "\n",
    "# Required columns\n",
    "required = {\"user_id\", \"cutoff\", \"split\", \"y_purchase\", \"y_revenue\"}\n",
    "missing = sorted(list(required - set(df.columns)))\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "# Feature columns: exclude ids/labels/meta\n",
    "drop_cols = {\"user_id\", \"cutoff\", \"split\", \"y_purchase\", \"y_revenue\"}\n",
    "feature_cols = [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "print(\"n_features:\", len(feature_cols))\n",
    "print(\"features:\", feature_cols)\n",
    "\n",
    "# Ensure numeric (simple guard)\n",
    "non_numeric = [c for c in feature_cols if not pd.api.types.is_numeric_dtype(df[c])]\n",
    "if non_numeric:\n",
    "    raise ValueError(f\"Non-numeric features found (please remove or encode): {non_numeric}\")\n",
    "\n",
    "# Split datasets\n",
    "train = df[df[\"split\"] == \"train\"].copy()\n",
    "valid = df[df[\"split\"] == \"valid\"].copy()\n",
    "test  = df[df[\"split\"] == \"test\"].copy()\n",
    "\n",
    "print(\"Splits:\", train.shape, valid.shape, test.shape)\n",
    "print(\"Base rates:\", train[\"y_purchase\"].mean(), valid[\"y_purchase\"].mean(), test[\"y_purchase\"].mean())\n",
    "\n",
    "# Buyers only for value model training\n",
    "train_b = train[train[\"y_purchase\"] == 1].copy()\n",
    "valid_b = valid[valid[\"y_purchase\"] == 1].copy()\n",
    "\n",
    "print(\"Buyers (train/valid):\", len(train_b), len(valid_b))\n",
    "print(\"Train buyers revenue summary:\")\n",
    "display(train_b[\"y_revenue\"].astype(float).describe(percentiles=[0.5, 0.9, 0.95, 0.99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa7be406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train/y_train: (939, 14) (939,)\n",
      "X_valid/y_valid: (576, 14) (576,)\n"
     ]
    }
   ],
   "source": [
    "# ============ Build training matrices (buyers only) ============\n",
    "X_train = train_b[feature_cols]\n",
    "y_train = np.log1p(train_b[\"y_revenue\"].astype(float).values)\n",
    "\n",
    "X_valid = valid_b[feature_cols]\n",
    "y_valid = np.log1p(valid_b[\"y_revenue\"].astype(float).values)\n",
    "\n",
    "print(\"X_train/y_train:\", X_train.shape, y_train.shape)\n",
    "print(\"X_valid/y_valid:\", X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a5f21b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.2091521\ttest: 1.3226943\tbest: 1.3226943 (0)\ttotal: 132ms\tremaining: 6m 34s\n",
      "200:\tlearn: 0.5864884\ttest: 0.8296902\tbest: 0.8170357 (93)\ttotal: 625ms\tremaining: 8.7s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.817035672\n",
      "bestIteration = 93\n",
      "\n",
      "Shrink model to first 94 iterations.\n",
      "Saved model: C:\\Users\\seony\\Desktop\\personal_project\\purchase_prediction\\artifacts\\models\\value_model_catboost.cbm\n"
     ]
    }
   ],
   "source": [
    "# ============ Train value model (CatBoostRegressor) ============\n",
    "model = CatBoostRegressor(\n",
    "    loss_function=\"RMSE\",\n",
    "    iterations=3000,\n",
    "    learning_rate=0.05,\n",
    "    depth=8,\n",
    "    l2_leaf_reg=5.0,\n",
    "    random_seed=42,\n",
    "    early_stopping_rounds=200,\n",
    "    verbose=200,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_valid, y_valid),\n",
    "    use_best_model=True,\n",
    ")\n",
    "\n",
    "model.save_model(VALUE_MODEL_OUT)\n",
    "print(\"Saved model:\", VALUE_MODEL_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f9ced2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\seony\\Desktop\\personal_project\\purchase_prediction\\artifacts\\metrics\\value_metrics_valid.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rmse_log1p</td>\n",
       "      <td>0.817036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mae_log1p</td>\n",
       "      <td>0.565461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rmse_revenue</td>\n",
       "      <td>413.484198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mae_revenue</td>\n",
       "      <td>182.608939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n_valid_buyers</td>\n",
       "      <td>576.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           metric       value\n",
       "0      rmse_log1p    0.817036\n",
       "1       mae_log1p    0.565461\n",
       "2    rmse_revenue  413.484198\n",
       "3     mae_revenue  182.608939\n",
       "4  n_valid_buyers  576.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============ Validate value model (buyers only) ============\n",
    "pred_valid_log = model.predict(X_valid)\n",
    "\n",
    "mse_log = mean_squared_error(y_valid, pred_valid_log)\n",
    "rmse_log = float(np.sqrt(mse_log))\n",
    "mae_log = float(mean_absolute_error(y_valid, pred_valid_log))\n",
    "\n",
    "# Back to revenue scale (still conditional)\n",
    "pred_valid_rev = np.expm1(pred_valid_log)\n",
    "pred_valid_rev = np.clip(pred_valid_rev, 0.0, None)\n",
    "\n",
    "y_valid_rev = valid_b[\"y_revenue\"].astype(float).values\n",
    "\n",
    "mse_rev = mean_squared_error(y_valid_rev, pred_valid_rev)\n",
    "rmse_rev = float(np.sqrt(mse_rev))\n",
    "mae_rev = float(mean_absolute_error(y_valid_rev, pred_valid_rev))\n",
    "\n",
    "metrics = pd.DataFrame([{\n",
    "    \"metric\": \"rmse_log1p\",\n",
    "    \"value\": rmse_log,\n",
    "}, {\n",
    "    \"metric\": \"mae_log1p\",\n",
    "    \"value\": mae_log,\n",
    "}, {\n",
    "    \"metric\": \"rmse_revenue\",\n",
    "    \"value\": rmse_rev,\n",
    "}, {\n",
    "    \"metric\": \"mae_revenue\",\n",
    "    \"value\": mae_rev,\n",
    "}, {\n",
    "    \"metric\": \"n_valid_buyers\",\n",
    "    \"value\": int(len(valid_b)),\n",
    "}])\n",
    "\n",
    "metrics.to_csv(VALUE_METRICS_OUT, index=False)\n",
    "print(\"Saved:\", VALUE_METRICS_OUT)\n",
    "display(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78c61c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rev_hat VALID summary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    278847.000000\n",
       "mean        158.066742\n",
       "std         153.967285\n",
       "min           4.639130\n",
       "50%         105.041504\n",
       "90%         395.953174\n",
       "95%         490.927582\n",
       "99%         656.772644\n",
       "max         764.813171\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rev_hat TEST summary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    253026.000000\n",
       "mean        167.910706\n",
       "std         159.685059\n",
       "min           4.541190\n",
       "50%         110.524063\n",
       "90%         410.902618\n",
       "95%         509.188370\n",
       "99%         656.772644\n",
       "max         766.440430\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============ Predict rev_hat for VALID/TEST (all users) ============\n",
    "# The model is trained on buyers, but we generate rev_hat for all rows for EV ranking.\n",
    "\n",
    "valid_all = valid.copy()\n",
    "test_all  = test.copy()\n",
    "\n",
    "rev_hat_valid = np.expm1(model.predict(valid_all[feature_cols]))\n",
    "rev_hat_test  = np.expm1(model.predict(test_all[feature_cols]))\n",
    "\n",
    "rev_hat_valid = np.clip(rev_hat_valid, 0.0, None).astype(\"float32\")\n",
    "rev_hat_test  = np.clip(rev_hat_test, 0.0, None).astype(\"float32\")\n",
    "\n",
    "valid_all[\"rev_hat\"] = rev_hat_valid\n",
    "test_all[\"rev_hat\"]  = rev_hat_test\n",
    "\n",
    "print(\"rev_hat VALID summary:\")\n",
    "display(pd.Series(rev_hat_valid).describe(percentiles=[0.5, 0.9, 0.95, 0.99]))\n",
    "print(\"rev_hat TEST summary:\")\n",
    "display(pd.Series(rev_hat_test).describe(percentiles=[0.5, 0.9, 0.95, 0.99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e44da49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated predictions:\n",
      " - C:\\Users\\seony\\Desktop\\personal_project\\purchase_prediction\\artifacts\\predictions\\predictions_valid_raw.csv\n",
      " - C:\\Users\\seony\\Desktop\\personal_project\\purchase_prediction\\artifacts\\predictions\\predictions_test_raw.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>y_purchase</th>\n",
       "      <th>y_revenue</th>\n",
       "      <th>p_hat</th>\n",
       "      <th>p_hat_model</th>\n",
       "      <th>rev_hat</th>\n",
       "      <th>ev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1515915625353230683</td>\n",
       "      <td>2020-12-27 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128091</td>\n",
       "      <td>catboost</td>\n",
       "      <td>370.060394</td>\n",
       "      <td>47.401447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1515915625353234047</td>\n",
       "      <td>2020-12-27 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110201</td>\n",
       "      <td>catboost</td>\n",
       "      <td>31.809345</td>\n",
       "      <td>3.505434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1515915625353294441</td>\n",
       "      <td>2020-12-27 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531393</td>\n",
       "      <td>catboost</td>\n",
       "      <td>224.598969</td>\n",
       "      <td>119.350327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1515915625353400724</td>\n",
       "      <td>2020-12-27 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573701</td>\n",
       "      <td>catboost</td>\n",
       "      <td>99.288689</td>\n",
       "      <td>56.962048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1515915625353416040</td>\n",
       "      <td>2020-12-27 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.734995</td>\n",
       "      <td>catboost</td>\n",
       "      <td>177.451233</td>\n",
       "      <td>130.425858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id                    cutoff  y_purchase  y_revenue  \\\n",
       "0  1515915625353230683 2020-12-27 00:00:00+00:00           0        0.0   \n",
       "1  1515915625353234047 2020-12-27 00:00:00+00:00           0        0.0   \n",
       "2  1515915625353294441 2020-12-27 00:00:00+00:00           0        0.0   \n",
       "3  1515915625353400724 2020-12-27 00:00:00+00:00           0        0.0   \n",
       "4  1515915625353416040 2020-12-27 00:00:00+00:00           0        0.0   \n",
       "\n",
       "      p_hat p_hat_model     rev_hat          ev  \n",
       "0  0.128091    catboost  370.060394   47.401447  \n",
       "1  0.110201    catboost   31.809345    3.505434  \n",
       "2  0.531393    catboost  224.598969  119.350327  \n",
       "3  0.573701    catboost   99.288689   56.962048  \n",
       "4  0.734995    catboost  177.451233  130.425858  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============ Update predictions files from notebook 02 (add rev_hat + ev) ============\n",
    "# We join on (user_id, cutoff). Cutoff must match as datetime.\n",
    "\n",
    "pred_valid = pd.read_csv(PRED_VALID_RAW)\n",
    "pred_test  = pd.read_csv(PRED_TEST_RAW)\n",
    "\n",
    "# Parse cutoff\n",
    "pred_valid[\"cutoff\"] = pd.to_datetime(pred_valid[\"cutoff\"], utc=True, errors=\"coerce\")\n",
    "pred_test[\"cutoff\"]  = pd.to_datetime(pred_test[\"cutoff\"],  utc=True, errors=\"coerce\")\n",
    "\n",
    "join_cols = [\"user_id\", \"cutoff\"]\n",
    "\n",
    "add_valid = valid_all[join_cols + [\"rev_hat\"]]\n",
    "add_test  = test_all[join_cols + [\"rev_hat\"]]\n",
    "\n",
    "m_valid = pred_valid.merge(add_valid, on=join_cols, how=\"left\")\n",
    "m_test  = pred_test.merge(add_test,  on=join_cols, how=\"left\")\n",
    "\n",
    "if m_valid[\"rev_hat\"].isna().any() or m_test[\"rev_hat\"].isna().any():\n",
    "    n1 = int(m_valid[\"rev_hat\"].isna().sum())\n",
    "    n2 = int(m_test[\"rev_hat\"].isna().sum())\n",
    "    raise ValueError(f\"rev_hat merge produced NaNs (valid={n1}, test={n2}). Check join keys and cutoff parsing.\")\n",
    "\n",
    "m_valid[\"rev_hat\"] = m_valid[\"rev_hat\"].astype(\"float32\")\n",
    "m_test[\"rev_hat\"]  = m_test[\"rev_hat\"].astype(\"float32\")\n",
    "\n",
    "# EV for ranking\n",
    "m_valid[\"ev\"] = (m_valid[\"p_hat\"].astype(float) * m_valid[\"rev_hat\"].astype(float)).astype(\"float32\")\n",
    "m_test[\"ev\"]  = (m_test[\"p_hat\"].astype(float) * m_test[\"rev_hat\"].astype(float)).astype(\"float32\")\n",
    "\n",
    "# Overwrite raw prediction files (still \"raw\" for p_hat; needed before calibration)\n",
    "m_valid.to_csv(PRED_VALID_RAW, index=False)\n",
    "m_test.to_csv(PRED_TEST_RAW, index=False)\n",
    "\n",
    "print(\"Updated predictions:\")\n",
    "print(\" -\", PRED_VALID_RAW)\n",
    "print(\" -\", PRED_TEST_RAW)\n",
    "\n",
    "display(m_valid.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1ca5e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean rev_hat by y_purchase (VALID):\n",
      "y_purchase\n",
      "0    157.881317\n",
      "1    247.642517\n",
      "Name: rev_hat, dtype: float32\n",
      "\n",
      "Mean ev by y_purchase (VALID):\n",
      "y_purchase\n",
      "0     50.853775\n",
      "1    184.175293\n",
      "Name: ev, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# ============ Quick sanity: buyers should have higher revenue on average ============\n",
    "tmp = m_valid.copy()\n",
    "tmp[\"y_purchase\"] = tmp[\"y_purchase\"].astype(int)\n",
    "\n",
    "print(\"Mean rev_hat by y_purchase (VALID):\")\n",
    "print(tmp.groupby(\"y_purchase\")[\"rev_hat\"].mean())\n",
    "\n",
    "print(\"\\nMean ev by y_purchase (VALID):\")\n",
    "print(tmp.groupby(\"y_purchase\")[\"ev\"].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
